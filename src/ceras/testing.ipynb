{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f260d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82be8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amanc\\anaconda3\\envs\\ceras\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa3559ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanc\\AppData\\Local\\Temp\\ipykernel_14732\\3938246654.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model='llama3.2')\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b75cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# --- small safe wrapper to call your llm variable (handles common call styles) ---\n",
    "def call_llm(prompt: str) -> str:\n",
    "    try:\n",
    "        out = llm(prompt)                 # callable\n",
    "        if isinstance(out, str): return out\n",
    "        if hasattr(out, 'text'): return out.text\n",
    "        return str(out)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        out = llm.generate(prompt)       # .generate()\n",
    "        if isinstance(out, str): return out\n",
    "        if isinstance(out, dict) and 'choices' in out:\n",
    "            return ''.join(c.get('content','') for c in out['choices'])\n",
    "        if hasattr(out, 'text'): return out.text\n",
    "        return str(out)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        out = llm.complete(prompt)       # .complete()\n",
    "        if isinstance(out, str): return out\n",
    "        if hasattr(out, 'text'): return out.text\n",
    "        return str(out)\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"Unable to call llm. Ensure `llm` is callable or supports .generate/.complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee08a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- decomposition prompt (concise, JSON-first) ---\n",
    "DECOMP_PROMPT = (\n",
    "    \"You are a reasoning engine. Decompose the user's problem into a short ordered list \"\n",
    "    \"of clear, atomic subtasks needed to solve it.\\n\"\n",
    "    \"Return output as JSON: {{ \\\"subtasks\\\": [ ... ] }} if possible. Be concise.\\n\"\n",
    "    \"User query: \\\"\\\"\\\"{query}\\\"\\\"\\\"\"\n",
    ")\n",
    "\n",
    "# --- function that returns list of subtasks only ---\n",
    "def decompose_query(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Call the llm and return a list of subtasks.\n",
    "    This version avoids KeyError by escaping literal braces in the prompt.\n",
    "    \"\"\"\n",
    "    raw = call_llm(DECOMP_PROMPT.format(query=query))\n",
    "    raw = (raw or \"\").strip()\n",
    "    # Try JSON parse first\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "        if isinstance(obj, dict) and 'subtasks' in obj and isinstance(obj['subtasks'], list):\n",
    "            return [s.strip() for s in obj['subtasks'] if isinstance(s, str) and s.strip()]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Try to find a JSON-like substring inside the model output\n",
    "    try:\n",
    "        jmatch = re.search(r'\\{.*\"subtasks\".*\\}', raw, flags=re.S)\n",
    "        if jmatch:\n",
    "            obj = json.loads(jmatch.group(0))\n",
    "            if isinstance(obj, dict) and 'subtasks' in obj and isinstance(obj['subtasks'], list):\n",
    "                return [s.strip() for s in obj['subtasks'] if isinstance(s, str) and s.strip()]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Heuristic fallback: split numbered or dashed lists\n",
    "    lines = []\n",
    "    for line in raw.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # drop common leading markers\n",
    "        line = re.sub(r'^[0-9]+[)\\.\\-\\s]+', '', line)\n",
    "        line = re.sub(r'^[-*\\u2022]\\s*', '', line)\n",
    "        # ignore long narrative lines that don't look like steps\n",
    "        if 3 <= len(line) <= 300:\n",
    "            lines.append(line)\n",
    "    if lines:\n",
    "        return lines\n",
    "    # Last resort: return the original query as single step\n",
    "    return [query.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3929c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- small runner that prints + returns subtasks ---\n",
    "def run_decomposer(query: str):\n",
    "    subtasks = decompose_query(query)\n",
    "    print(\"Subtasks:\")\n",
    "    for i, s in enumerate(subtasks, 1):\n",
    "        print(f\" {i}. {s}\")\n",
    "    return subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff909b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2fe75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4f4aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amanc\\AppData\\Local\\Temp\\ipykernel_14732\\1816498432.py:7: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  out = llm(prompt)                 # callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Install necessary libraries (e.g., requests, Pillow)\n",
      " 2. Create a list of URLs for images to download\n",
      " 3. Download each image from URL and save as temporary file\n",
      " 4. Use Pillow to resize each image to 512x512\n",
      " 5. Convert resized image to PNG format and save\n",
      "['Install necessary libraries (e.g., requests, Pillow)', 'Create a list of URLs for images to download', 'Download each image from URL and save as temporary file', 'Use Pillow to resize each image to 512x512', 'Convert resized image to PNG format and save']\n"
     ]
    }
   ],
   "source": [
    "subtasks = run_decomposer(\"Write a Python script that downloads images from a URL list, resizes them to 512x512, and saves as PNG.\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "164fbf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. { \"subtasks\": [\n",
      " 2. Identify the type of plane engine (e.g. turbofan, turboprop, jet engine),\n",
      " 3. Research the current design specifications and performance characteristics of the engine,\n",
      " 4. Explore aerodynamic and thermodynamic optimization techniques for increasing engine speed,\n",
      " 5. Investigate advanced materials or manufacturing techniques that could improve engine durability and efficiency,\n",
      " 6. Consider modifying the engine's compressor, turbine, or nozzle to increase airflow, pressure ratio, or exhaust velocity\n",
      " 7. ] }\n",
      "['{ \"subtasks\": [', 'Identify the type of plane engine (e.g. turbofan, turboprop, jet engine),', 'Research the current design specifications and performance characteristics of the engine,', 'Explore aerodynamic and thermodynamic optimization techniques for increasing engine speed,', 'Investigate advanced materials or manufacturing techniques that could improve engine durability and efficiency,', \"Consider modifying the engine's compressor, turbine, or nozzle to increase airflow, pressure ratio, or exhaust velocity\", '] }']\n"
     ]
    }
   ],
   "source": [
    "subtasks = run_decomposer(\"how to make a plane engine faster?\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f930de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "subtasks = run_decomposer(\"how to develop an app in flutter\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2530058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "\n",
    "# Strong JSON-first prompt (use f-string to avoid brace escaping)\n",
    "DECOMP_PROMPT_JSON = (\n",
    "    \"You are a reasoning engine. Decompose the user's problem into a short ordered list of clear, \"\n",
    "    \"atomic subtasks needed to solve it. OUTPUT MUST BE STRICT JSON and nothing else, like:\\n\"\n",
    "    '{\"subtasks\": [\"step1\", \"step2\", ...]}\\n\\n'\n",
    "    \"Be concise. Do not add commentary.\\n\\n\"\n",
    "    \"User query:\\n\"\n",
    "    \"'''{query}'''\\n\"\n",
    ")\n",
    "\n",
    "DECOMP_PROMPT_SIMPLE = (\n",
    "    \"Decompose the user's request into a short ordered list of subtasks (plain text lines). \"\n",
    "    \"Return only the list (one step per line). Keep steps atomic and actionable.\\n\\n\"\n",
    "    \"User query:\\n\"\n",
    "    \"'''{query}'''\\n\"\n",
    ")\n",
    "\n",
    "def heuristic_fallback_for_query(query: str):\n",
    "    \"\"\"Deterministic fallback if LLM fails. Returns a reasonable generic decomposition for common tasks.\"\"\"\n",
    "    q = query.lower()\n",
    "    # If it's about building an app (mobile/web) produce a standard flow\n",
    "    if any(w in q for w in (\"app\", \"application\", \"flutter\", \"react native\", \"android\", \"ios\")):\n",
    "        return [\n",
    "            \"Define app purpose, target users, and core features\",\n",
    "            \"Design UI/UX sketches and basic navigation flow\",\n",
    "            \"Choose tech stack and set up project (Flutter SDK, project structure)\",\n",
    "            \"Implement core screens and navigation\",\n",
    "            \"Implement data layer (local storage / API integration)\",\n",
    "            \"Add assets and handle media/sizes\",\n",
    "            \"Implement app logic and state management\",\n",
    "            \"Test features locally (emulator / device) and fix bugs\",\n",
    "            \"Prepare release (signing, build flavors) and deploy to app store / Play Store\",\n",
    "            \"Plan post-release monitoring and updates\"\n",
    "        ]\n",
    "    # If it's a generic 'how to' question give general research/decomposition steps\n",
    "    return [\n",
    "        \"Clarify objective and desired outcome\",\n",
    "        \"List required inputs and constraints\",\n",
    "        \"Break the task into 3–6 atomic steps\",\n",
    "        \"For each step, identify necessary tools or resources\",\n",
    "        \"Execute steps in order, verify results after each\",\n",
    "        \"Summarize and document the final result\"\n",
    "    ]\n",
    "\n",
    "def parse_json_subtasks(raw: str):\n",
    "    \"\"\"Try to safely extract JSON substring with 'subtasks' and return list or None.\"\"\"\n",
    "    if not raw:\n",
    "        return None\n",
    "    raw = raw.strip()\n",
    "    # try direct parse\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "        if isinstance(obj, dict) and 'subtasks' in obj and isinstance(obj['subtasks'], list):\n",
    "            return [s.strip() for s in obj['subtasks'] if isinstance(s, str) and s.strip()]\n",
    "    except Exception:\n",
    "        pass\n",
    "    # try to find JSON-like block\n",
    "    jmatch = re.search(r'\\{[^}]*\"subtasks\"[^}]*\\}', raw, flags=re.S)\n",
    "    if jmatch:\n",
    "        try:\n",
    "            obj = json.loads(jmatch.group(0))\n",
    "            if isinstance(obj, dict) and 'subtasks' in obj and isinstance(obj['subtasks'], list):\n",
    "                return [s.strip() for s in obj['subtasks'] if isinstance(s, str) and s.strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def decompose_query(query: str) -> list:\n",
    "    # 1) Try strict JSON output from LLM\n",
    "    try:\n",
    "        raw = call_llm(DECOMP_PROMPT_JSON.format(query=query))\n",
    "    except Exception:\n",
    "        raw = \"\"\n",
    "    parsed = parse_json_subtasks(raw)\n",
    "    if parsed:\n",
    "        return parsed\n",
    "\n",
    "    # 2) Retry with a simpler plain-list prompt\n",
    "    try:\n",
    "        raw2 = call_llm(DECOMP_PROMPT_SIMPLE.format(query=query))\n",
    "    except Exception:\n",
    "        raw2 = \"\"\n",
    "    # try to extract lines from raw2\n",
    "    lines = []\n",
    "    if raw2:\n",
    "        for line in raw2.splitlines():\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # drop leading bullets/numbers\n",
    "            line = re.sub(r'^[0-9]+[)\\.\\-\\s]+', '', line)\n",
    "            line = re.sub(r'^[-*\\u2022]\\s*', '', line)\n",
    "            if 3 <= len(line) <= 300:\n",
    "                lines.append(line)\n",
    "    if lines:\n",
    "        return lines\n",
    "\n",
    "    # 3) Deterministic heuristic fallback based on query\n",
    "    return heuristic_fallback_for_query(query)\n",
    "\n",
    "def run_decomposer(query: str):\n",
    "    subtasks = decompose_query(query)\n",
    "    print(\"Subtasks:\")\n",
    "    for i, s in enumerate(subtasks, 1):\n",
    "        print(f\" {i}. {s}\")\n",
    "    return subtasks\n",
    "\n",
    "# --- quick local test (you can run this) ---\n",
    "# subtasks = run_decomposer(\"how to develop an app in flutter\")\n",
    "# print(subtasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af1222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Define app purpose, target users, and core features\n",
      " 2. Design UI/UX sketches and basic navigation flow\n",
      " 3. Choose tech stack and set up project (Flutter SDK, project structure)\n",
      " 4. Implement core screens and navigation\n",
      " 5. Implement data layer (local storage / API integration)\n",
      " 6. Add assets and handle media/sizes\n",
      " 7. Implement app logic and state management\n",
      " 8. Test features locally (emulator / device) and fix bugs\n",
      " 9. Prepare release (signing, build flavors) and deploy to app store / Play Store\n",
      " 10. Plan post-release monitoring and updates\n",
      "['Define app purpose, target users, and core features', 'Design UI/UX sketches and basic navigation flow', 'Choose tech stack and set up project (Flutter SDK, project structure)', 'Implement core screens and navigation', 'Implement data layer (local storage / API integration)', 'Add assets and handle media/sizes', 'Implement app logic and state management', 'Test features locally (emulator / device) and fix bugs', 'Prepare release (signing, build flavors) and deploy to app store / Play Store', 'Plan post-release monitoring and updates']\n"
     ]
    }
   ],
   "source": [
    "subtasks = run_decomposer(\"how to develop an app in flutter\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63f02d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Clarify objective and desired outcome\n",
      " 2. List required inputs and constraints\n",
      " 3. Break the task into 3–6 atomic steps\n",
      " 4. For each step, identify necessary tools or resources\n",
      " 5. Execute steps in order, verify results after each\n",
      " 6. Summarize and document the final result\n",
      "['Clarify objective and desired outcome', 'List required inputs and constraints', 'Break the task into 3–6 atomic steps', 'For each step, identify necessary tools or resources', 'Execute steps in order, verify results after each', 'Summarize and document the final result']\n"
     ]
    }
   ],
   "source": [
    "subtasks = run_decomposer(\"how high is the sky\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a509c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f57601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amanc\\anaconda3\\envs\\ceras\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\amanc\\Desktop\\ceras\\src\\ceras\\llm_utils.py:5: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL)\n",
      "c:\\Users\\amanc\\Desktop\\ceras\\src\\ceras\\llm_utils.py:27: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  out = llm(prompt)                 # callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Identify the algebraic expression (a^2 - b^2) as a difference of squares.\n",
      " 2. Recognize the formula for factoring a difference of squares: (x + y)(x - y).\n",
      " 3. Apply the formula to factor (a^2 - b^2): (a+b)(a-b).\n",
      " 4. Simplify the expression if necessary.\n",
      " 5. Find an efficient method to solve the resulting expression, such as expanding it or using algebraic identities.\n",
      "['Identify the algebraic expression (a^2 - b^2) as a difference of squares.', 'Recognize the formula for factoring a difference of squares: (x + y)(x - y).', 'Apply the formula to factor (a^2 - b^2): (a+b)(a-b).', 'Simplify the expression if necessary.', 'Find an efficient method to solve the resulting expression, such as expanding it or using algebraic identities.']\n"
     ]
    }
   ],
   "source": [
    "from llm_utils import run_decomposer\n",
    "\n",
    "subtasks = run_decomposer(\"what is (a^2 - b^2)? how can i solve it effeciently?\")\n",
    "print(subtasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b3c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "from langchain.llms import Ollama\n",
    "llm_verify = Ollama(model='mistral')  # used for verification + repair\n",
    "from llm_utils import run_decomposer\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utility: JSON extraction\n",
    "# -------------------------\n",
    "def extract_json_from_text(text: str) -> Any:\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Find first JSON block manually\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start != -1 and end != -1:\n",
    "        try:\n",
    "            return json.loads(text[start:end + 1])\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise ValueError(\"Could not extract JSON from verifier output.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Subtask normalization\n",
    "# -------------------------\n",
    "def _make_subtask_dict(id_: str = None, inp: str = \"\", out: str = \"\") -> Dict[str, str]:\n",
    "    return {\"id\": id_ or str(uuid.uuid4()), \"input\": inp or \"\", \"output\": out or \"\"}\n",
    "\n",
    "\n",
    "def normalize_subtasks(raw_subtasks: Union[str, Dict, List, Tuple, Any]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Convert run_decomposer output into canonical list of dicts\"\"\"\n",
    "    if isinstance(raw_subtasks, list):\n",
    "        normalized = []\n",
    "        for item in raw_subtasks:\n",
    "            if isinstance(item, dict):\n",
    "                sid = item.get(\"id\") or item.get(\"name\") or str(uuid.uuid4())\n",
    "                inp = item.get(\"input\") if item.get(\"input\") is not None else item.get(\"prompt\", \"\")\n",
    "                out = item.get(\"output\") if item.get(\"output\") is not None else item.get(\"result\") or item.get(\"answer\") or \"\"\n",
    "                normalized.append(_make_subtask_dict(sid, str(inp), str(out)))\n",
    "            elif isinstance(item, (tuple, list)):\n",
    "                if len(item) == 2:\n",
    "                    inp, out = item\n",
    "                    normalized.append(_make_subtask_dict(str(uuid.uuid4()), str(inp), str(out)))\n",
    "                elif len(item) >= 3:\n",
    "                    sid, inp, out = item[0], item[1], item[2]\n",
    "                    normalized.append(_make_subtask_dict(str(sid), str(inp), str(out)))\n",
    "            else:\n",
    "                normalized.append(_make_subtask_dict(None, \"\", str(item)))\n",
    "        return normalized\n",
    "\n",
    "    if isinstance(raw_subtasks, dict):\n",
    "        if all(not isinstance(v, (dict, list, tuple)) for v in raw_subtasks.values()):\n",
    "            normalized = []\n",
    "            for k, v in raw_subtasks.items():\n",
    "                normalized.append(_make_subtask_dict(str(k), \"\", str(v)))\n",
    "            return normalized\n",
    "        else:\n",
    "            sid = raw_subtasks.get(\"id\") or raw_subtasks.get(\"name\") or str(uuid.uuid4())\n",
    "            inp = raw_subtasks.get(\"input\") or raw_subtasks.get(\"prompt\") or \"\"\n",
    "            out = raw_subtasks.get(\"output\") or raw_subtasks.get(\"result\") or raw_subtasks.get(\"answer\") or \"\"\n",
    "            return [_make_subtask_dict(sid, str(inp), str(out))]\n",
    "\n",
    "    return [_make_subtask_dict(None, \"\", str(raw_subtasks))]\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Prompt builders\n",
    "# -------------------------\n",
    "def build_verifier_prompt(task_id: str, original_prompt: str, subtasks: List[Dict[str, Any]], constraints: List[str] = None) -> str:\n",
    "    constraints = constraints or []\n",
    "    constraints_text = \"\\n\".join(f\"- {c}\" for c in constraints) if constraints else \"None\"\n",
    "    subs = normalize_subtasks(subtasks)\n",
    "\n",
    "    subtasks_text = \"\"\n",
    "    for s in subs:\n",
    "        sid = s.get(\"id\") or str(uuid.uuid4())\n",
    "        inp = s.get(\"input\", \"\")\n",
    "        out = s.get(\"output\", \"\")\n",
    "        subtasks_text += f\"ID: {sid}\\nINPUT: {inp}\\nOUTPUT: {out}\\n---\\n\"\n",
    "\n",
    "    schema = {\n",
    "        \"task_id\": \"string\",\n",
    "        \"verifications\": [\n",
    "            {\n",
    "                \"subtask_id\": \"string\",\n",
    "                \"verdict\": \"accept|partial_accept|reject\",\n",
    "                \"score\": \"0.0\",\n",
    "                \"issues\": [\"string\", \"...\"],\n",
    "                \"suggested_fix\": \"string (optional)\",\n",
    "                \"confidence_interval\": [0.0, 1.0],\n",
    "                \"evidence\": \"string\"\n",
    "            }\n",
    "        ],\n",
    "        \"aggregate_decision\": \"accept|partial_accept|repair_required|escalate\",\n",
    "        \"repair_plan\": {\"type\": \"auto|human_review|call_producer\", \"instructions\": \"string\"}\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a verification model. ONLY output a single JSON object following this schema exactly. No extra commentary.\n",
    "\n",
    "SCHEMA: {json.dumps(schema, indent=2)}\n",
    "\n",
    "TASK_ID: {task_id}\n",
    "\n",
    "Original prompt:\n",
    "{original_prompt}\n",
    "\n",
    "Constraints:\n",
    "{constraints_text}\n",
    "\n",
    "Subtasks:\n",
    "{subtasks_text}\n",
    "\n",
    "Return the JSON object now.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "def build_repair_prompt(original_prompt: str, subtask: Dict[str, Any], verifier_issues: List[str]) -> str:\n",
    "    return f\"\"\"\n",
    "You are a repair model. The original overall prompt:\n",
    "{original_prompt}\n",
    "\n",
    "Subtask ID: {subtask.get('id')}\n",
    "Subtask input:\n",
    "{subtask.get('input')}\n",
    "\n",
    "Subtask current output:\n",
    "{subtask.get('output')}\n",
    "\n",
    "Verifier issues:\n",
    "{json.dumps(verifier_issues, indent=2)}\n",
    "\n",
    "Please return JSON:\n",
    "{{ \"subtask_id\": \"<id>\", \"corrected_output\": \"<fixed output>\", \"justification\": \"<1-2 sentence reason>\" }}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Verification + repair\n",
    "# -------------------------\n",
    "def run_verification_and_repair(\n",
    "    task_id: str,\n",
    "    original_prompt: str,\n",
    "    subtasks: List[Dict[str, Any]],\n",
    "    constraints: List[str] = None,\n",
    "    max_repair_attempts: int = 2,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Run the mistral verifier (via Ollama) on subtasks and optionally auto-repair.\"\"\"\n",
    "    # 1. Verification\n",
    "    verifier_prompt = build_verifier_prompt(task_id, original_prompt, subtasks, constraints)\n",
    "    raw_verifier_out = llm_verify(verifier_prompt)\n",
    "    try:\n",
    "        verifier_json = extract_json_from_text(raw_verifier_out)\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"task_id\": task_id,\n",
    "            \"error\": \"verifier_parse_failed\",\n",
    "            \"raw_output\": raw_verifier_out,\n",
    "            \"exception\": str(e),\n",
    "        }\n",
    "\n",
    "    verifications = verifier_json.get(\"verifications\", [])\n",
    "    aggregate_decision = verifier_json.get(\"aggregate_decision\", \"repair_required\")\n",
    "    verif_by_id = {v.get(\"subtask_id\"): v for v in verifications if \"subtask_id\" in v}\n",
    "\n",
    "    subtasks_by_id = {s.get(\"id\", str(uuid.uuid4())): dict(s) for s in normalize_subtasks(subtasks)}\n",
    "    repair_history = []\n",
    "\n",
    "    # 2. Repair loop\n",
    "    for sub_id, sub in subtasks_by_id.items():\n",
    "        v = verif_by_id.get(sub_id)\n",
    "        verdict = v.get(\"verdict\") if v else \"partial_accept\"\n",
    "        issues = v.get(\"issues\", []) if v else []\n",
    "\n",
    "        if verdict == \"accept\":\n",
    "            continue\n",
    "\n",
    "        # Try auto repair\n",
    "        for attempt in range(max_repair_attempts):\n",
    "            repair_prompt = build_repair_prompt(original_prompt, sub, issues)\n",
    "            raw_repair_out = llm_verify(repair_prompt)\n",
    "            try:\n",
    "                repair_json = extract_json_from_text(raw_repair_out)\n",
    "                corrected = repair_json.get(\"corrected_output\")\n",
    "                sub[\"output\"] = corrected\n",
    "                repair_history.append(\n",
    "                    {\n",
    "                        \"subtask_id\": sub_id,\n",
    "                        \"attempt\": attempt + 1,\n",
    "                        \"corrected_output\": corrected,\n",
    "                        \"justification\": repair_json.get(\"justification\"),\n",
    "                    }\n",
    "                )\n",
    "                # re-verify this subtask\n",
    "                recheck_prompt = build_verifier_prompt(task_id + f\"__recheck_{sub_id}\", original_prompt, [sub], constraints)\n",
    "                raw_recheck = llm_verify(recheck_prompt)\n",
    "                recheck_json = extract_json_from_text(raw_recheck)\n",
    "                verdict = recheck_json[\"verifications\"][0][\"verdict\"]\n",
    "                if verdict == \"accept\":\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                repair_history.append({\"subtask_id\": sub_id, \"error\": str(e)})\n",
    "                break\n",
    "\n",
    "    # 3. Final aggregation of subtasks + verifier decisions\n",
    "    final_subtasks = []\n",
    "    for sub_id, sub in subtasks_by_id.items():\n",
    "        v = verif_by_id.get(sub_id, {})\n",
    "        final_subtasks.append(\n",
    "            {\n",
    "                \"id\": sub_id,\n",
    "                \"input\": sub.get(\"input\"),\n",
    "                \"output\": sub.get(\"output\"),\n",
    "                \"verdict\": v.get(\"verdict\", \"unknown\"),\n",
    "                \"score\": v.get(\"score\"),\n",
    "                \"issues\": v.get(\"issues\"),\n",
    "                \"evidence\": v.get(\"evidence\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"original_prompt\": original_prompt,\n",
    "        \"aggregate_decision\": aggregate_decision,\n",
    "        \"verifier_raw\": verifier_json,\n",
    "        \"final_subtasks\": final_subtasks,\n",
    "        \"repair_history\": repair_history,\n",
    "        \"timestamp\": time.time(),\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Aggregator\n",
    "# -------------------------\n",
    "def aggregate_final_answer(verified_result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    accepted_outputs = [\n",
    "        s.get(\"output\", \"\").strip()\n",
    "        for s in verified_result.get(\"final_subtasks\", [])\n",
    "        if s.get(\"verdict\") in (\"accept\", \"partial_accept\")\n",
    "    ]\n",
    "    return {\n",
    "        \"task_id\": verified_result[\"task_id\"],\n",
    "        \"final_answer\": \"\\n\\n\".join(accepted_outputs).strip(),\n",
    "        \"aggregate_decision\": verified_result.get(\"aggregate_decision\"),\n",
    "        \"provenance\": {\n",
    "            \"verifier\": verified_result.get(\"verifier_raw\"),\n",
    "            \"repair_history\": verified_result.get(\"repair_history\"),\n",
    "        },\n",
    "        \"timestamp\": time.time(),\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Pipeline Entry\n",
    "# -------------------------\n",
    "def run_inference_pipeline(prompt: str, task_id: str = None, constraints: List[str] = None) -> Dict[str, Any]:\n",
    "    task_id = task_id or f\"task_{int(time.time())}\"\n",
    "    raw_subtasks = run_decomposer(prompt)\n",
    "    print(f\"[DEBUG] Decomposer returned type={type(raw_subtasks)}\")\n",
    "\n",
    "    subtasks = normalize_subtasks(raw_subtasks)\n",
    "    verified = run_verification_and_repair(task_id, prompt, subtasks, constraints or [])\n",
    "    final = aggregate_final_answer(verified)\n",
    "    return {\"task_id\": task_id, \"original_prompt\": prompt, \"verified\": verified, \"final\": final}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5175edc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Expand the given expression a^2 - b^2 using algebraic identities.\n",
      " 2. Simplify the expanded expression to obtain its simplified form.\n",
      " 3. Identify any patterns or factorable terms within the simplified expression.\n",
      " 4. Apply factoring techniques (if applicable) to further simplify the expression.\n",
      " 5. Provide an efficient method for calculating the value of the simplified expression.\n",
      "[DEBUG] Decomposer returned type=<class 'list'>\n",
      "{\n",
      "  \"task_id\": \"task_1762583871\",\n",
      "  \"final_answer\": \"Expand the given expression a^2 - b^2 using algebraic identities.\\n\\nSimplify the expanded expression to obtain its simplified form.\\n\\nIdentify any patterns or factorable terms within the simplified expression.\\n\\nProvide an efficient method for calculating the value of the simplified expression.\",\n",
      "  \"aggregate_decision\": \"accept\",\n",
      "  \"provenance\": {\n",
      "    \"verifier\": {\n",
      "      \"task_id\": \"task_1762583871\",\n",
      "      \"verifications\": [\n",
      "        {\n",
      "          \"subtask_id\": \"5a4c3c0d-83c7-4f59-8209-0991cae4d83f\",\n",
      "          \"verdict\": \"accept\",\n",
      "          \"score\": 1.0,\n",
      "          \"issues\": [],\n",
      "          \"suggested_fix\": \"\",\n",
      "          \"confidence_interval\": [\n",
      "            0.0,\n",
      "            1.0\n",
      "          ],\n",
      "          \"evidence\": \"a^2 - b^2 can be expanded using the distributive property of multiplication over subtraction: (a + (-b))*(a - b)\"\n",
      "        },\n",
      "        {\n",
      "          \"subtask_id\": \"72e4a8ee-dc55-4ab5-b67d-107fbcf6b967\",\n",
      "          \"verdict\": \"accept\",\n",
      "          \"score\": 1.0,\n",
      "          \"issues\": [],\n",
      "          \"suggested_fix\": \"\",\n",
      "          \"confidence_interval\": [\n",
      "            0.0,\n",
      "            1.0\n",
      "          ],\n",
      "          \"evidence\": \"(a + (-b))*(a - b) = a^2 - b^2 - ab + ab = a^2 - b^2\"\n",
      "        },\n",
      "        {\n",
      "          \"subtask_id\": \"33b092f3-bdd5-4ad9-8f88-e22ea4a7ef66\",\n",
      "          \"verdict\": \"accept\",\n",
      "          \"score\": 1.0,\n",
      "          \"issues\": [],\n",
      "          \"suggested_fix\": \"\",\n",
      "          \"confidence_interval\": [\n",
      "            0.0,\n",
      "            1.0\n",
      "          ],\n",
      "          \"evidence\": \"No patterns or factorable terms are found within a^2 - b^2\"\n",
      "        },\n",
      "        {\n",
      "          \"subtask_id\": \"83d2db82-c296-45eb-af14-f20bcec6df87\",\n",
      "          \"verdict\": \"reject\",\n",
      "          \"score\": 0.0,\n",
      "          \"issues\": [\n",
      "            \"No factoring techniques are applicable to the given expression\"\n",
      "          ],\n",
      "          \"suggested_fix\": \"\",\n",
      "          \"confidence_interval\": [\n",
      "            0.0,\n",
      "            1.0\n",
      "          ],\n",
      "          \"evidence\": \"\"\n",
      "        },\n",
      "        {\n",
      "          \"subtask_id\": \"0265bd47-1c5e-46e3-a585-ced2f6eeac88\",\n",
      "          \"verdict\": \"accept\",\n",
      "          \"score\": 1.0,\n",
      "          \"issues\": [],\n",
      "          \"suggested_fix\": \"\",\n",
      "          \"confidence_interval\": [\n",
      "            0.0,\n",
      "            1.0\n",
      "          ],\n",
      "          \"evidence\": \"To calculate the value of a^2 - b^2, you can simply substitute the values for 'a' and 'b'\"\n",
      "        }\n",
      "      ],\n",
      "      \"aggregate_decision\": \"accept\",\n",
      "      \"repair_plan\": {\n",
      "        \"type\": \"none\",\n",
      "        \"instructions\": \"\"\n",
      "      }\n",
      "    },\n",
      "    \"repair_history\": [\n",
      "      {\n",
      "        \"subtask_id\": \"83d2db82-c296-45eb-af14-f20bcec6df87\",\n",
      "        \"attempt\": 1,\n",
      "        \"corrected_output\": \"The expression (a^2 - b^2) can be simplified by recognizing it as the difference of squares. The simplified form is (a + b)(a - b).\",\n",
      "        \"justification\": \"This is a result from basic algebraic properties, where the square of a binomial can be expanded and rearranged.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"timestamp\": 1762583989.060974\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_prompt = \"what is (a^2 - b^2)? how can i solve it efficiently?\"\n",
    "out = run_inference_pipeline(example_prompt)\n",
    "print(json.dumps(out[\"final\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20d8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55ac7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ca963f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Determine the scope of each domain (arrays, strings, hashing, graphs) for the interview.\n",
      " 2. Identify key concepts and common problems within each domain.\n",
      " 3. Develop a list of potential questions or problems for each domain.\n",
      " 4. Prioritize the questions based on difficulty and relevance to DSA knowledge.\n",
      " 5. Outline a general structure for the interview, including format (e.g., take-home, in-person) and length.\n",
      " 6. Decide on the number of questions or problems to include in the interview plan.\n",
      " 7. Create a draft of the interview questions and problems, ensuring they meet the required scope and difficulty levels.\n",
      " 8. Review and refine the interview plan to ensure it effectively tests DSA knowledge for all domains.\n",
      "[DEBUG] run_decomposer returned type=<class 'list'>, preview=['Determine the scope of each domain (arrays, strings, hashing, graphs) for the interview.', 'Identify key concepts and common problems within each domain.', 'Develop a list of potential questions or problems for each domain.', 'Prioritize the questions based on difficulty and relevance to DSA knowl\n",
      "{\n",
      "  \"status\": \"accepted\",\n",
      "  \"message\": \"Subtasks sufficient. Forwarding inference.\",\n",
      "  \"final_subtasks\": [\n",
      "    {\n",
      "      \"id\": \"339741d7-7150-4a04-adfe-5bb8333b3505\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Determine the scope of each domain (arrays, strings, hashing, graphs) for the interview.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"6a6c037d-2da3-448d-81c6-6e31a2c24d0b\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Identify key concepts and common problems within each domain.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"73b2fc6c-55c1-49cd-a91c-bf8cdcd0f739\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Develop a list of potential questions or problems for each domain.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"5b26d196-2e9f-4d82-8507-cc03e796a7be\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Prioritize the questions based on difficulty and relevance to DSA knowledge.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"978b91f4-88a8-45f3-aac2-ca7ba8e4a262\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Outline a general structure for the interview, including format (e.g., take-home, in-person) and length.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"d7f6ca04-2d7f-4075-8a84-0124202a1724\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Decide on the number of questions or problems to include in the interview plan.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"322cf5ce-d619-4604-a36d-6b7cd4c3dd58\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Create a draft of the interview questions and problems, ensuring they meet the required scope and difficulty levels.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"8f593674-ebca-4808-92ad-7702d4cbc262\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Review and refine the interview plan to ensure it effectively tests DSA knowledge for all domains.\"\n",
      "    }\n",
      "  ],\n",
      "  \"timestamp\": 1762585069.1374454,\n",
      "  \"raw_verifier\": {\n",
      "    \"accept_all\": true,\n",
      "    \"missing\": [],\n",
      "    \"suggestions\": []\n",
      "  },\n",
      "  \"suggestions\": [],\n",
      "  \"missing\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# fast_inference_final_subtasks.py\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "llm_verify = Ollama(model='mistral')  # small, fast verifier (must be configured in your env)\n",
    "\n",
    "# try to import user's decomposer, else fallback\n",
    "from llm_utils import run_decomposer  \n",
    "\n",
    "\n",
    "# --- helpers (same as before) ---\n",
    "def _make_subtask_dict(id_: str = None, inp: str = \"\", out: str = \"\") -> Dict[str, str]:\n",
    "    return {\"id\": id_ or str(uuid.uuid4()), \"input\": inp or \"\", \"output\": out or \"\"}\n",
    "\n",
    "\n",
    "def normalize_subtasks(raw_subtasks: Union[str, Dict, List, Any]) -> List[Dict[str, str]]:\n",
    "    if isinstance(raw_subtasks, list):\n",
    "        normalized = []\n",
    "        for item in raw_subtasks:\n",
    "            if isinstance(item, dict):\n",
    "                sid = item.get(\"id\") or item.get(\"name\") or str(uuid.uuid4())\n",
    "                inp = item.get(\"input\") if item.get(\"input\") is not None else item.get(\"prompt\", \"\")\n",
    "                out = item.get(\"output\") if item.get(\"output\") is not None else item.get(\"result\") or item.get(\"answer\") or \"\"\n",
    "                normalized.append(_make_subtask_dict(sid, str(inp), str(out)))\n",
    "            elif isinstance(item, (tuple, list)):\n",
    "                if len(item) == 2:\n",
    "                    inp, out = item\n",
    "                    normalized.append(_make_subtask_dict(str(uuid.uuid4()), str(inp), str(out)))\n",
    "                elif len(item) >= 3:\n",
    "                    sid, inp, out = item[0], item[1], item[2]\n",
    "                    normalized.append(_make_subtask_dict(str(sid), str(inp), str(out)))\n",
    "                else:\n",
    "                    normalized.append(_make_subtask_dict(None, \"\", str(item)))\n",
    "            else:\n",
    "                normalized.append(_make_subtask_dict(None, \"\", str(item)))\n",
    "        return normalized\n",
    "\n",
    "    if isinstance(raw_subtasks, dict):\n",
    "        if all(not isinstance(v, (dict, list, tuple)) for v in raw_subtasks.values()):\n",
    "            normalized = []\n",
    "            for k, v in raw_subtasks.items():\n",
    "                normalized.append(_make_subtask_dict(str(k), \"\", str(v)))\n",
    "            return normalized\n",
    "        else:\n",
    "            sid = raw_subtasks.get(\"id\") or raw_subtasks.get(\"name\") or str(uuid.uuid4())\n",
    "            inp = raw_subtasks.get(\"input\") or raw_subtasks.get(\"prompt\") or \"\"\n",
    "            out = raw_subtasks.get(\"output\") or raw_subtasks.get(\"result\") or raw_subtasks.get(\"answer\") or \"\"\n",
    "            return [_make_subtask_dict(sid, str(inp), str(out))]\n",
    "\n",
    "    return [_make_subtask_dict(None, \"\", str(raw_subtasks))]\n",
    "\n",
    "\n",
    "def extract_json_from_text(text: str) -> Any:\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    s = text.find(\"{\")\n",
    "    e = text.rfind(\"}\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        try:\n",
    "            return json.loads(text[s:e+1])\n",
    "        except Exception:\n",
    "            pass\n",
    "    s = text.find(\"[\")\n",
    "    e = text.rfind(\"]\")\n",
    "    if s != -1 and e != -1 and e > s:\n",
    "        try:\n",
    "            return json.loads(text[s:e+1])\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise ValueError(\"No JSON found in verifier output.\")\n",
    "\n",
    "\n",
    "# --- compact verifier prompt ---\n",
    "def build_quick_verifier_prompt(original_prompt: str, subtasks: List[Dict[str, Any]], domain_hint: str = \"\") -> str:\n",
    "    brief = \"\"\n",
    "    for i, s in enumerate(subtasks, start=1):\n",
    "        text = s.get(\"input\") or s.get(\"output\") or \"\"\n",
    "        brief += f\"{i}. {text}\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a fast verifier. Given the original task and the list of subtasks below, answer in JSON only:\\n\"\n",
    "        \" - 'accept_all': boolean, are these subtasks sufficient to solve the main task?\\n\"\n",
    "        \" - 'missing': short list of missing concepts or checks (if any)\\n\"\n",
    "        \" - 'suggestions': short list of short suggested subtasks to add (if any)\\n\\n\"\n",
    "        f\"Domain: {domain_hint}\\n\"\n",
    "        f\"Original task: {original_prompt}\\n\"\n",
    "        f\"Subtasks:\\n{brief}\\n\"\n",
    "        \"Return EXACT JSON like: {\\\"accept_all\\\": true, \\\"missing\\\": [], \\\"suggestions\\\": []}\\n\"\n",
    "        \"Output only JSON.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# --- fast verifier call ---\n",
    "def fast_verify_subtasks(original_prompt: str, raw_subtasks: Union[List[Any], Any], domain_hint: str = \"\") -> Dict[str, Any]:\n",
    "    subtasks = normalize_subtasks(raw_subtasks)\n",
    "    prompt = build_quick_verifier_prompt(original_prompt, subtasks, domain_hint)\n",
    "    raw = llm_verify(prompt)\n",
    "    try:\n",
    "        parsed = extract_json_from_text(raw)\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"accept_all\": False,\n",
    "            \"missing\": [\"verifier_parse_failed\"],\n",
    "            \"suggestions\": [\"Please retry verification or use a different verifier model.\"],\n",
    "            \"subtasks\": subtasks,\n",
    "            \"raw_verifier\": raw\n",
    "        }\n",
    "\n",
    "    accept_all = bool(parsed.get(\"accept_all\")) if isinstance(parsed, dict) else False\n",
    "    missing = parsed.get(\"missing\") if isinstance(parsed, dict) else []\n",
    "    suggestions = parsed.get(\"suggestions\") if isinstance(parsed, dict) else []\n",
    "\n",
    "    return {\n",
    "        \"accept_all\": accept_all,\n",
    "        \"missing\": missing or [],\n",
    "        \"suggestions\": suggestions or [],\n",
    "        \"subtasks\": subtasks,\n",
    "        \"raw_verifier\": parsed\n",
    "    }\n",
    "\n",
    "\n",
    "# --- updated run_inference_pipeline_fast that always returns final_subtasks ---\n",
    "def run_inference_pipeline_fast(\n",
    "    prompt: str,\n",
    "    domain_hint: str = \"\",\n",
    "    auto_extend: bool = False,\n",
    "    keep_suggestions_field: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns a dict containing:\n",
    "      - status: 'accepted'|'insufficient'\n",
    "      - final_subtasks: canonical forwardable subtasks (possibly extended if auto_extend=True)\n",
    "      - suggestions, missing, raw_verifier\n",
    "    \"\"\"\n",
    "    raw = run_decomposer(prompt)\n",
    "    print(f\"[DEBUG] run_decomposer returned type={type(raw)}, preview={str(raw)[:300]}\")\n",
    "\n",
    "    check = fast_verify_subtasks(prompt, raw, domain_hint=domain_hint)\n",
    "\n",
    "    canonical = check[\"subtasks\"]  # list of canonical subtask dicts\n",
    "\n",
    "    final_subtasks = [dict(s) for s in canonical]  # shallow copy\n",
    "\n",
    "    if check[\"accept_all\"]:\n",
    "        status = \"accepted\"\n",
    "        message = \"Subtasks sufficient. Forwarding inference.\"\n",
    "    else:\n",
    "        status = \"insufficient\"\n",
    "        message = \"Verifier flagged missing points or insufficiencies.\"\n",
    "        # If auto_extend, append suggestion strings as new subtasks with empty output\n",
    "        if auto_extend and check.get(\"suggestions\"):\n",
    "            for s in check[\"suggestions\"]:\n",
    "                final_subtasks.append(_make_subtask_dict(None, s, \"\"))\n",
    "        # else leave final_subtasks as canonical (caller can handle suggestions)\n",
    "\n",
    "    result = {\n",
    "        \"status\": status,\n",
    "        \"message\": message,\n",
    "        \"final_subtasks\": final_subtasks,\n",
    "        \"timestamp\": time.time(),\n",
    "        \"raw_verifier\": check.get(\"raw_verifier\")\n",
    "    }\n",
    "\n",
    "    if keep_suggestions_field:\n",
    "        result[\"suggestions\"] = check.get(\"suggestions\", [])\n",
    "        result[\"missing\"] = check.get(\"missing\", [])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- quick test ---\n",
    "if __name__ == \"__main__\":\n",
    "    example_prompt = \"Design an interview plan to test DSA knowledge for arrays, strings, hashing, and graphs.\"\n",
    "    out = run_inference_pipeline_fast(example_prompt, domain_hint=\"DSA\", auto_extend=True)\n",
    "    print(json.dumps(out, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4104cf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL SUBTASKS TO FORWARD ===\n",
      " [\n",
      "  {\n",
      "    \"id\": \"339741d7-7150-4a04-adfe-5bb8333b3505\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Determine the scope of each domain (arrays, strings, hashing, graphs) for the interview.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"6a6c037d-2da3-448d-81c6-6e31a2c24d0b\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Identify key concepts and common problems within each domain.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"73b2fc6c-55c1-49cd-a91c-bf8cdcd0f739\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Develop a list of potential questions or problems for each domain.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"5b26d196-2e9f-4d82-8507-cc03e796a7be\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Prioritize the questions based on difficulty and relevance to DSA knowledge.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"978b91f4-88a8-45f3-aac2-ca7ba8e4a262\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Outline a general structure for the interview, including format (e.g., take-home, in-person) and length.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"d7f6ca04-2d7f-4075-8a84-0124202a1724\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Decide on the number of questions or problems to include in the interview plan.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"322cf5ce-d619-4604-a36d-6b7cd4c3dd58\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Create a draft of the interview questions and problems, ensuring they meet the required scope and difficulty levels.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"8f593674-ebca-4808-92ad-7702d4cbc262\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Review and refine the interview plan to ensure it effectively tests DSA knowledge for all domains.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL SUBTASKS TO FORWARD ===\\n\", json.dumps(out[\"final_subtasks\"], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f55beb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Start by learning the basics of dynamic programming using online tutorials or introductory books.\n",
      " 2. Identify specific areas of dynamic programming that are confusing (e.g., memoization, tabulation).\n",
      " 3. Find step-by-step explanations or video lectures on those specific topics.\n",
      " 4. Practice solving problems related to those areas to reinforce understanding.\n",
      " 5. Join online communities or forums to ask questions and get help from others who have experience with dynamic programming.\n",
      " 6. Look for courses or tutorials that cater to beginners, such as Coursera's \"Dynamic Programming\" course by Stanford University.\n",
      "[DEBUG] run_decomposer returned type=<class 'list'>, preview=['Start by learning the basics of dynamic programming using online tutorials or introductory books.', 'Identify specific areas of dynamic programming that are confusing (e.g., memoization, tabulation).', 'Find step-by-step explanations or video lectures on those specific topics.', 'Practice solving \n",
      "{\n",
      "  \"status\": \"accepted\",\n",
      "  \"message\": \"Subtasks sufficient. Forwarding inference.\",\n",
      "  \"final_subtasks\": [\n",
      "    {\n",
      "      \"id\": \"257f4b82-3dfd-4532-b027-670173820fef\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Start by learning the basics of dynamic programming using online tutorials or introductory books.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"4a0151f3-36ae-429c-b64e-48b4b91118bb\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Identify specific areas of dynamic programming that are confusing (e.g., memoization, tabulation).\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"717c7484-9b2c-4be4-a63c-ef218e35c6d9\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Find step-by-step explanations or video lectures on those specific topics.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"6a79b3c5-3a6d-42b1-ada8-1cc707a0e2e8\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Practice solving problems related to those areas to reinforce understanding.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"acd5e2c0-2642-4516-bcb1-6979773f354b\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Join online communities or forums to ask questions and get help from others who have experience with dynamic programming.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"9a7eb2af-ec16-4684-af13-f6ceb797f7f8\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Look for courses or tutorials that cater to beginners, such as Coursera's \\\"Dynamic Programming\\\" course by Stanford University.\"\n",
      "    }\n",
      "  ],\n",
      "  \"timestamp\": 1762585215.9502192,\n",
      "  \"raw_verifier\": {\n",
      "    \"accept_all\": true,\n",
      "    \"missing\": [],\n",
      "    \"suggestions\": []\n",
      "  },\n",
      "  \"suggestions\": [],\n",
      "  \"missing\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_prompt = \"i want to learn dynammic programming but i am not able to understand the advanced concepts. what should i do?\"\n",
    "out = run_inference_pipeline_fast(example_prompt, domain_hint=\"DSA\", auto_extend=True)\n",
    "print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb69c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL SUBTASKS TO FORWARD ===\n",
      " [\n",
      "  {\n",
      "    \"id\": \"257f4b82-3dfd-4532-b027-670173820fef\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Start by learning the basics of dynamic programming using online tutorials or introductory books.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"4a0151f3-36ae-429c-b64e-48b4b91118bb\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Identify specific areas of dynamic programming that are confusing (e.g., memoization, tabulation).\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"717c7484-9b2c-4be4-a63c-ef218e35c6d9\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Find step-by-step explanations or video lectures on those specific topics.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"6a79b3c5-3a6d-42b1-ada8-1cc707a0e2e8\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Practice solving problems related to those areas to reinforce understanding.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"acd5e2c0-2642-4516-bcb1-6979773f354b\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Join online communities or forums to ask questions and get help from others who have experience with dynamic programming.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9a7eb2af-ec16-4684-af13-f6ceb797f7f8\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Look for courses or tutorials that cater to beginners, such as Coursera's \\\"Dynamic Programming\\\" course by Stanford University.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL SUBTASKS TO FORWARD ===\\n\", json.dumps(out[\"final_subtasks\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50d295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtasks:\n",
      " 1. Identify suitable online language learning platforms or resources.\n",
      " 2. Determine the level of French proficiency desired (beginner, intermediate, advanced).\n",
      " 3. Set a realistic study schedule and create a dedicated study space.\n",
      " 4. Select a French language course or textbook to follow.\n",
      " 5. Find a language exchange partner or tutor for conversational practice.\n",
      "[DEBUG] run_decomposer returned type=<class 'list'>, preview=['Identify suitable online language learning platforms or resources.', 'Determine the level of French proficiency desired (beginner, intermediate, advanced).', 'Set a realistic study schedule and create a dedicated study space.', 'Select a French language course or textbook to follow.', 'Find a lang\n",
      "{\n",
      "  \"status\": \"accepted\",\n",
      "  \"message\": \"Subtasks sufficient. Forwarding inference.\",\n",
      "  \"final_subtasks\": [\n",
      "    {\n",
      "      \"id\": \"d38d0fdf-9348-4dad-a042-b0048f2095e4\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Identify suitable online language learning platforms or resources.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"747ff395-313e-4d4d-af76-4f6556c4143f\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Determine the level of French proficiency desired (beginner, intermediate, advanced).\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"49eb0c06-e5c0-4e52-829b-64baba4f1c12\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Set a realistic study schedule and create a dedicated study space.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"9636e595-8c98-4163-9fdd-e666934ec737\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Select a French language course or textbook to follow.\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"248a69b3-0bba-4a94-a322-4a54f49fd002\",\n",
      "      \"input\": \"\",\n",
      "      \"output\": \"Find a language exchange partner or tutor for conversational practice.\"\n",
      "    }\n",
      "  ],\n",
      "  \"timestamp\": 1762585397.7795143,\n",
      "  \"raw_verifier\": {\n",
      "    \"accept_all\": true,\n",
      "    \"missing\": [],\n",
      "    \"suggestions\": [\n",
      "      \"Practice listening to French music or watching French movies for cultural immersion.\",\n",
      "      \"Learn and practice French grammar rules.\"\n",
      "    ]\n",
      "  },\n",
      "  \"suggestions\": [\n",
      "    \"Practice listening to French music or watching French movies for cultural immersion.\",\n",
      "    \"Learn and practice French grammar rules.\"\n",
      "  ],\n",
      "  \"missing\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "example_prompt = \"how do i learn french?\"\n",
    "out = run_inference_pipeline_fast(example_prompt,auto_extend=True)\n",
    "print(json.dumps(out, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "828e618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL SUBTASKS TO FORWARD ===\n",
      " [\n",
      "  {\n",
      "    \"id\": \"d38d0fdf-9348-4dad-a042-b0048f2095e4\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Identify suitable online language learning platforms or resources.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"747ff395-313e-4d4d-af76-4f6556c4143f\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Determine the level of French proficiency desired (beginner, intermediate, advanced).\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"49eb0c06-e5c0-4e52-829b-64baba4f1c12\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Set a realistic study schedule and create a dedicated study space.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"9636e595-8c98-4163-9fdd-e666934ec737\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Select a French language course or textbook to follow.\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"248a69b3-0bba-4a94-a322-4a54f49fd002\",\n",
      "    \"input\": \"\",\n",
      "    \"output\": \"Find a language exchange partner or tutor for conversational practice.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FINAL SUBTASKS TO FORWARD ===\\n\", json.dumps(out[\"final_subtasks\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5aad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FORMATTED FINAL SUBTASKS ===\n",
      "1. Identify suitable online language learning platforms or resources.\n",
      "2. Determine the level of French proficiency desired (beginner, intermediate, advanced).\n",
      "3. Set a realistic study schedule and create a dedicated study space.\n",
      "4. Select a French language course or textbook to follow.\n",
      "5. Find a language exchange partner or tutor for conversational practice.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FORMATTED FINAL SUBTASKS ===\")\n",
    "for i, s in enumerate(out[\"final_subtasks\"], start=1):\n",
    "    text = s.get(\"input\") or s.get(\"output\") or \"\"\n",
    "    print(f\"{i}. {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
